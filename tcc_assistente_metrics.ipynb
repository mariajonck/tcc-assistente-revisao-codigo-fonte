{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação e configuração do ambiente\n",
        "\n",
        "Esta célula instala as dependências necessárias para a execução do experimento. Inclui a configuração do Java 22, essencial para o funcionamento das ferramentas CK e Designite, além da instalação do Maven e das bibliotecas Python para análise e aprendizado de máquina.\n",
        "\n",
        "É necessária a substituição do OpenJDK 17 para a versão 22, para o funcionamento da ferramente Designite.\n",
        "\n"
      ],
      "metadata": {
        "id": "9A12vnLxxzE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyGithub\n"
      ],
      "metadata": {
        "id": "mGXCUYwpr9bS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/adoptium/temurin22-binaries/releases/download/jdk-22.0.2%2B9/OpenJDK22U-jdk_x64_linux_hotspot_22.0.2_9.tar.gz\n",
        "!tar -xzf OpenJDK22U-jdk_x64_linux_hotspot_22.0.2_9.tar.gz\n",
        "!mv jdk-22.0.2+9 /usr/local/jdk-22\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Dy1JBhKlUKL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/java java /usr/local/jdk-22/bin/java 1\n",
        "!sudo update-alternatives --set java /usr/local/jdk-22/bin/java\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RIyjt2QDUNwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export JAVA_HOME=/usr/local/jdk-22/bin/java\n",
        "!export PATH=$JAVA_HOME/bin:$PATH\n"
      ],
      "metadata": {
        "id": "3rII-bcZ3BwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mauricioaniche/ck.git /content/ck"
      ],
      "metadata": {
        "id": "-kSSNTbZ-zKC",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ck\n",
        "!./mvnw clean package -Dmaven.javadoc.skip=true -DskipTests\n"
      ],
      "metadata": {
        "id": "Eqw77lgrQH57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/designite\n",
        "\n",
        "!wget https://www.designite-tools.com/assets/DesigniteJava.jar -O DesigniteJava.jar /content/designite\n"
      ],
      "metadata": {
        "id": "57ELueRXClMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/ck/DesigniteJava.jar /content/designite/\n",
        "!ls -lh /content/designite/"
      ],
      "metadata": {
        "id": "acmLt9jBB1-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clonagem e preparação dos repositórios\n",
        "\n",
        "Nesta etapa, são clonados projetos Java open source que servirão de base para a análise, incluindo java-design-patterns, EvoSuite, SonarQube. Esses repositórios representam diferentes estilos de código e padrões arquiteturais, oferecendo diversidade para o conjunto de dados."
      ],
      "metadata": {
        "id": "nfy-Li3By7_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/iluwatar/java-design-patterns.git repos_java/java-design-patterns\n",
        "!git clone https://github.com/EvoSuite/evosuite.git repos_java/evosuite\n",
        "!git clone https://github.com/SonarSource/sonarqube.git repos_java/sonarqube\n"
      ],
      "metadata": {
        "id": "1CBGJmMSz0XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução da ferramenta Designite\n",
        "\n",
        "A ferramenta DesigniteJava é usada para detectar automaticamente code smells de diferentes categorias: Design Smells, Implementation Smells, Architecture Smells e Test Smells.\n",
        "\n",
        "Cada análise gera um conjunto de arquivos .csv por projeto, listando classes e tipos de smells detectados.\n",
        "Em seguida, todos os arquivos são consolidados em um dataset unificado (designite_dataset.csv)."
      ],
      "metadata": {
        "id": "_LT5ceaEzb4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import glob\n",
        "import os\n",
        "\n",
        "designite_path = \"/content/designite/DesigniteJava.jar\"\n",
        "base_path = \"/content/ck/repos_java\"\n",
        "\n",
        "java_paths = glob.glob(f\"{base_path}/**/src/main/java\", recursive=True)\n",
        "\n",
        "print(f\"{len(java_paths)} projetos detectados com código-fonte Java.\\n\")\n",
        "\n",
        "for path in java_paths:\n",
        "    project_dir = os.path.abspath(os.path.join(path, \"../../..\"))\n",
        "    output_dir = os.path.join(project_dir, \"designite_output\")\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    print(f\"Analisando projeto: {project_dir}\")\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"java\", \"-jar\", designite_path, \"-i\", project_dir, \"-o\", output_dir],\n",
        "            check=True\n",
        "        )\n",
        "        print(f\"Análise concluída: {output_dir}\\n\")\n",
        "        type_metrics_file = os.path.join(output_dir, \"TypeMetrics.csv\")\n",
        "        if os.path.exists(type_metrics_file):\n",
        "            with open(type_metrics_file, \"r\") as f:\n",
        "                class_count = sum(1 for _ in f) - 1\n",
        "            print(f\"→ Classes analisadas pelo Designite: {class_count}\")\n",
        "\n",
        "        java_files = glob.glob(f\"{project_dir}/**/*.java\", recursive=True)\n",
        "        print(f\"→ Arquivos Java encontrados: {len(java_files)}\\n\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Erro ao analisar {project_dir}: {e}\\n\")\n"
      ],
      "metadata": {
        "id": "JjgqvS5q-3Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, os, glob\n",
        "\n",
        "designite_path = \"/content/designite/DesigniteJava.jar\"\n",
        "\n",
        "for repo in glob.glob(\"/content/ck/repos_java/*\"):\n",
        "    out_dir = os.path.join(repo, \"designite_output\")\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    cmd = [\"java\", \"-jar\", designite_path, \"-i\", repo, \"-o\", out_dir]\n",
        "    print(f\"Analisando {repo} ...\")\n",
        "    subprocess.run(cmd)\n"
      ],
      "metadata": {
        "id": "XXHY09OTC0gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "files = glob.glob(\"/content/ck/repos_java/*/designite_output/DesignSmells.csv\")\n",
        "df_list = [pd.read_csv(f) for f in files]\n",
        "df_smells = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "df_smells.to_csv(\"/content/dataset_code_smells.csv\", index=False)\n",
        "print(\"Dataset rotulado salvo como dataset_code_smells.csv\")\n"
      ],
      "metadata": {
        "id": "3Vm1nPxhC4cB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# caminhos dos resultados\n",
        "paths = glob.glob(\"/content/ck/repos_java/**/designite_output/*.csv\", recursive=True)\n",
        "\n",
        "# lista para armazenar todos os DataFrames\n",
        "frames = []\n",
        "\n",
        "for path in paths:\n",
        "    category = path.split(\"/\")[-1].replace(\".csv\", \"\")\n",
        "    df = pd.read_csv(path)\n",
        "    df[\"Category\"] = category  # adiciona a categoria (Design, Implementation, etc)\n",
        "    frames.append(df)\n",
        "\n",
        "dataset = pd.concat(frames, ignore_index=True)\n",
        "dataset.to_csv(\"/content/designite_dataset.csv\", index=False)\n",
        "\n",
        "print(f\"Dataset consolidado com {len(dataset)} registros salvo em /content/designite_dataset.csv\")\n",
        "print(\"Categorias encontradas:\", dataset['Category'].unique())\n"
      ],
      "metadata": {
        "id": "VQU-s9C0V6Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução da ferramenta CK\n",
        "\n",
        "A ferramenta CK Metrics é executada em todas as pastas que contêm código-fonte Java (src/main/java).\n",
        "Ela gera arquivos CSV contendo métricas estruturais de classes e métodos, como:\n",
        "\n",
        "\n",
        "*   WMC (Complexidade Ciclomática)\n",
        "*   CBO (Acoplamento)\n",
        "*   LCOM (Coesão)\n",
        "*   RFC (Resposta por Classe)\n",
        "*   LOC (Linhas de Código)\n",
        "\n",
        "Esses dados formam a base quantitativa para a detecção automática de code smells."
      ],
      "metadata": {
        "id": "z8tWsD6jzG4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "import glob\n",
        "\n",
        "ck_path = \"/content/ck/target/ck-0.7.1-SNAPSHOT-jar-with-dependencies.jar\"\n",
        "\n",
        "# pasta onde todos os repositórios estão clonados\n",
        "repos_root = \"/content/ck/repos_java\"\n",
        "\n",
        "# percorrer todas as pastas dos projetos que contenham 'src/main/java'\n",
        "java_paths = glob.glob(f\"{repos_root}/**/src/main/java\", recursive=True)\n",
        "\n",
        "print(f\"Total de pastas Java encontradas: {len(java_paths)}\\n\")\n",
        "\n",
        "for path in java_paths:\n",
        "    print(f\"Analisando pasta: {path}\")\n",
        "    output_dir = os.path.join(path, \"ck_output\")\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    subprocess.run([\n",
        "        \"java\", \"-jar\", ck_path,\n",
        "        path,\n",
        "        \"true\", \"0\", \"false\",\n",
        "        output_dir\n",
        "    ])"
      ],
      "metadata": {
        "id": "lz6N0Nyv-mj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geração de rótulos automáticos\n",
        "\n",
        "Como nem todas as classes possuem anotações manuais de smells, é feita uma rotulação heurística.\n",
        "Classes com valores acima da média para métricas como WMC, CBO, LCOM ou RFC são marcadas como code_smell = 1."
      ],
      "metadata": {
        "id": "IoOUCk1fz4KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "base_path = \"/content/ck/repos_java\"\n",
        "\n",
        "# (procura qualquer arquivo dentro de pastas que contenham 'ck_output')\n",
        "output_files = glob.glob(f\"{base_path}/**/ck_output*.csv\", recursive=True)\n",
        "print(f\"{len(output_files)} arquivos CSV encontrados para consolidação.\\n\")\n",
        "\n",
        "if not output_files:\n",
        "    raise FileNotFoundError(\"Nenhum arquivo de métricas CK encontrado nas pastas de saída.\")\n",
        "\n",
        "frames = []\n",
        "\n",
        "for f in output_files:\n",
        "    try:\n",
        "        df_part = pd.read_csv(f)\n",
        "        df_part[\"source_file\"] = os.path.basename(f)  # rastreabilidade\n",
        "        df_part[\"project\"] = f.split(\"/\")[3] if len(f.split(\"/\")) > 3 else \"unknown\"\n",
        "        frames.append(df_part)\n",
        "        print(f\"Lido: {f} ({df_part.shape[0]} linhas)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao ler {f}: {e}\")\n",
        "\n",
        "# Consolidar em um único DataFrame\n",
        "if frames:\n",
        "    df = pd.concat(frames, ignore_index=True)\n",
        "    print(f\"\\n dataset combinado com {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
        "\n",
        "    # criar coluna de rótulo\n",
        "    if {\"wmc\", \"cbo\", \"lcom\", \"rfc\"}.issubset(df.columns):\n",
        "        limiar_wmc = df[\"wmc\"].mean()\n",
        "        limiar_cbo = df[\"cbo\"].mean()\n",
        "        limiar_lcom = df[\"lcom\"].mean()\n",
        "        limiar_rfc = df[\"rfc\"].mean()\n",
        "\n",
        "        df[\"code_smell\"] = (\n",
        "            (df[\"wmc\"] > limiar_wmc) |\n",
        "            (df[\"cbo\"] > limiar_cbo) |\n",
        "            (df[\"lcom\"] > limiar_lcom) |\n",
        "            (df[\"rfc\"] > limiar_rfc)\n",
        "        ).astype(int)\n",
        "\n",
        "        print(f\"Rótulo 'code_smell' criado com base em múltiplas métricas (WMC, CBO, LCOM, RFC)\")\n",
        "    else:\n",
        "        df[\"code_smell\"] = 0\n",
        "        print(\"Métricas principais ausentes. Criada coluna 'code_smell' dummy = 0.\")\n",
        "\n",
        "    output_path = \"/content/dataset_metrics.csv\"\n",
        "    df.to_csv(output_path, index=False)\n",
        "    print(f\"\\nDataset consolidado salvo em: {output_path}\")\n",
        "else:\n",
        "    print(\"Nenhum arquivo CSV válido foi processado.\")\n"
      ],
      "metadata": {
        "id": "NlDYevxYrXAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['code_smell'].value_counts()"
      ],
      "metadata": {
        "id": "-z9eiUHEC_Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consolidação dos datasets\n",
        "\n",
        "Os arquivos gerados pelas ferramentas CK e Designite são integrados, formando o dataset final dataset_final.csv.\n",
        "A junção é realizada com base nos identificadores de arquivo e classe, combinando métricas estruturais (features) e rótulos de smells (labels).\n",
        "Esse dataset é a principal entrada para os modelos de aprendizado de máquina."
      ],
      "metadata": {
        "id": "S3K0AjQ-zoDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics = pd.read_csv(\"/content/dataset_metrics.csv\")\n",
        "df_smells = pd.read_csv(\"/content/designite_dataset.csv\")\n",
        "\n",
        "dataset_final = pd.merge(df_metrics, df_smells,\n",
        "                         left_on=[\"file\", \"class\"],\n",
        "                         right_on=[\"File\", \"Class\"],\n",
        "                         how=\"left\")\n",
        "\n",
        "dataset_final.to_csv(\"/content/dataset_final.csv\", index=False)\n",
        "print(\"Dataset final salvo como dataset_final.csv\")"
      ],
      "metadata": {
        "id": "VWxdrzhEC8Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Balanceamento de classes (SMOTE)\n",
        "\n",
        "O dataset costuma estar desbalanceado, com muito mais exemplos de classes \"limpas\" do que \"com smell\".\n",
        "Por isso, é aplicado o SMOTE (Synthetic Minority Over-sampling Technique), que cria amostras sintéticas da classe minoritária para melhorar o equilíbrio dos dados e evitar viés nos modelos.\n",
        "\n",
        "# Treinamento dos modelos de Machine Learning\n",
        "\n",
        "São avaliados dois algoritmos supervisionados:\n",
        "\n",
        "* Random Forest, com ajuste de parâmetros (n_estimators, max_depth, etc.) via GridSearchCV.\n",
        "\n",
        "* SVM (Support Vector Machine), com ajuste de C e gamma.\n",
        "\n",
        "As variáveis são normalizadas com StandardScaler, e a separação treino/teste é feita em 80/20, de forma estratificada.\n",
        "\n",
        "# Avaliação e comparação de desempenho\n",
        "\n",
        "Os modelos são avaliados com base nas métricas:\n",
        "\n",
        "* Acurácia, Precisão, Revocação e F1-Score\n",
        "\n",
        "* Matriz de Confusão para inspeção dos erros.\n",
        "\n",
        "Os resultados são comparados em um gráfico e salvos em resultados_modelos.csv.\n",
        "Essa etapa atende ao objetivo central de avaliar a eficácia dos algoritmos de aprendizado de máquina na classificação de code smells."
      ],
      "metadata": {
        "id": "q3ULUW1S1AQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score, make_scorer\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset_final.csv\")\n",
        "print(f\"Dataset carregado: {df.shape[0]} linhas e {df.shape[1]} colunas\\n\")\n",
        "\n",
        "df_numeric = df.select_dtypes(include=[\"int64\", \"float64\"]).dropna(axis=1, how=\"all\").fillna(0)\n",
        "\n",
        "if \"code_smell\" not in df_numeric.columns:\n",
        "    raise ValueError(\"A coluna 'code_smell' não foi encontrada no dataset!\")\n",
        "\n",
        "X = df_numeric.drop(columns=[\"code_smell\"])\n",
        "y = df_numeric[\"code_smell\"]\n",
        "\n",
        "print(f\"Variáveis de entrada: {X.shape[1]} | Classes: {y.value_counts().to_dict()}\\n\")\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "print(\"Validação cruzada configurada (10-Fold estratificada).\\n\")\n",
        "\n",
        "rf_pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('model', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "svm_pipeline = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', SVC(kernel='rbf', random_state=42))\n",
        "])\n",
        "\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "svm_params = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    'precision': make_scorer(precision_score, zero_division=0),\n",
        "    'recall': make_scorer(recall_score, zero_division=0),\n",
        "    'f1': make_scorer(f1_score, zero_division=0)\n",
        "}\n",
        "\n",
        "print(\"Ajustando hiperparâmetros com GridSearchCV\\n\")\n",
        "\n",
        "rf_grid = GridSearchCV(rf_pipeline, rf_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "svm_grid = GridSearchCV(svm_pipeline, svm_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "rf_grid.fit(X, y)\n",
        "svm_grid.fit(X, y)\n",
        "\n",
        "print(\"GridSearch finalizado!\")\n",
        "print(f\"Melhores parâmetros Random Forest: {rf_grid.best_params_}\")\n",
        "print(f\"Melhores parâmetros SVM: {svm_grid.best_params_}\\n\")\n",
        "\n",
        "def avaliar_modelo(modelo, nome):\n",
        "    resultados = cross_validate(\n",
        "        modelo, X, y,\n",
        "        cv=kfold, scoring=scoring,\n",
        "        n_jobs=-1, return_train_score=False\n",
        "    )\n",
        "    df_res = pd.DataFrame(resultados)\n",
        "    mean = df_res.mean()\n",
        "    std = df_res.std()\n",
        "    print(f\"\\n{nome} — Resultados médios (10-Fold):\")\n",
        "    print(mean[['test_accuracy', 'test_precision', 'test_recall', 'test_f1']])\n",
        "    return mean, std\n",
        "\n",
        "rf_mean, rf_std = avaliar_modelo(rf_grid.best_estimator_, \"Random Forest\")\n",
        "svm_mean, svm_std = avaliar_modelo(svm_grid.best_estimator_, \"SVM\")\n",
        "\n",
        "comparativo = pd.DataFrame({\n",
        "    'Modelo': ['Random Forest', 'SVM'],\n",
        "    'Acurácia Média': [rf_mean['test_accuracy'], svm_mean['test_accuracy']],\n",
        "    'Precisão Média': [rf_mean['test_precision'], svm_mean['test_precision']],\n",
        "    'Recall Médio': [rf_mean['test_recall'], svm_mean['test_recall']],\n",
        "    'F1-Score Médio': [rf_mean['test_f1'], svm_mean['test_f1']],\n",
        "    'Desvio Padrão (Acc)': [rf_std['test_accuracy'], svm_std['test_accuracy']]\n",
        "}).round(4)\n",
        "\n",
        "print(\"\\n=== Comparação Final (Média e Desvio-Padrão em 10-Fold) ===\\n\")\n",
        "print(comparativo)\n",
        "\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(7,4))\n",
        "sns.barplot(x='Modelo', y='Acurácia Média', data=comparativo, palette='Blues_d')\n",
        "plt.title(\"Comparação de Acurácia Média (10-Fold)\")\n",
        "plt.ylabel(\"Acurácia Média\")\n",
        "plt.xlabel(\"\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "comparativo.to_csv(\"/content/resultados.csv\", index=False)\n",
        "print(\"\\nResultados salvos em '/content/resultados.csv'\")"
      ],
      "metadata": {
        "id": "2WINAOvv6siq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "df = pd.read_csv(\"/content/dataset_final.csv\")\n",
        "df = df.select_dtypes(include=[\"int64\", \"float64\"]).dropna(axis=1, how=\"all\").fillna(0)\n",
        "\n",
        "X = df.drop(columns=[\"code_smell\"])\n",
        "y = df[\"code_smell\"]\n",
        "\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=2, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "svm = SVC(C=10, gamma=\"scale\", kernel=\"rbf\", random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "svm_pred = svm.predict(X_test_scaled)\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predito\")\n",
        "    plt.ylabel(\"Real\")\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(y_test, rf_pred, \"Matriz de Confusão — Random Forest\")\n",
        "plot_confusion_matrix(y_test, svm_pred, \"Matriz de Confusão — SVM\")"
      ],
      "metadata": {
        "id": "PPLXS6emrYGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hipóteses\n",
        "\n",
        " H₀ (nula): não há diferença significativa entre os modelos (as médias das métricas são iguais).\n",
        "\n",
        " H₁ (alternativa): há diferença significativa entre os modelos.\n",
        "\n",
        "# Aplicação do teste\n",
        "\n",
        "* Como os dois modelos são comparados sobre as mesmas dobras de dados, usa-se um teste pareado, como:\n",
        "\n",
        "  * Teste t de Student pareado, se os dados seguem distribuição normal;\n",
        "\n",
        "  * Teste de Wilcoxon signed-rank, se não houver normalidade (não paramétrico)."
      ],
      "metadata": {
        "id": "WQMZa5HNR62H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel, wilcoxon\n",
        "\n",
        "# valores de acurácia de cada modelo\n",
        "acc_rf = [1.0,1.0,1.0,1.0,1.0,1.0,0.9998189717595944,0.9998189717595944,1.0,1.0]\n",
        "acc_svm = [0.9780995475113122,0.9748416289592761,0.9777335264301231,0.9784576393917451,0.974475018102824,0.973388848660391,0.9764663287472846,0.9764663287472846,0.973388848660391,0.975199131064446]\n",
        "\n",
        "# Teste t pareado\n",
        "t_stat, p_val = ttest_rel(acc_rf, acc_svm)\n",
        "\n",
        "print(f\"t = {t_stat:.3f}, p = {p_val:.4f}\")\n",
        "\n",
        "if p_val < 0.05:\n",
        "    print(\"Diferença estatisticamente significativa (rejeita H0).\")\n",
        "else:\n",
        "    print(\"Sem diferença significativa (aceita H0).\")\n"
      ],
      "metadata": {
        "id": "ENKKQ5vvRwtd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}